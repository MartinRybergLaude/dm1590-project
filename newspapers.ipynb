{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: DM1590 Final Project Template\n",
    "\n",
    "## Authors: Markus Brewitz, Linus Wallin, Saga Jonasson, Vilhelm Norstr√∂m, Martin Ryberg Laude\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background and motivation\n",
    "\n",
    "News articles come in a variety of subjects and categories describing their field and relevance. Some of these have self-reported tags, but too many do not, or provide inaccurate tags. Tagging articles has the potential to help information-seekers to judge the relevance of articles and filter them by interest, especially in this day and age where information is so abundant it can be exhausting. In this project we set out to use machine learning to tag articles based on their titles, to aid the effort of searching for relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/News+Aggregator\n",
    "\n",
    "This dataset contains tags along with corresponding news titles, which we use to train our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "Describe what you are doing and how you are doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "column_names = [\"id\", \"title\", \"url\", \"publisher\", \"category\", \"story\", \"hostname\", \"timestamp\"]\n",
    "data = pd.read_csv('NewsAggregatorDataset/newsCorpora.csv',sep='\\t',header=None, names=column_names)\n",
    "corpus = data.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "corpus_train, corpus_test, y_train, y_test = train_test_split(corpus, data.category, train_size=0.7)\n",
    "\n",
    "# Vectorizing the train data\n",
    "vect = TfidfVectorizer(min_df=5)  # TODO: Experiment with the min_df value to find what works best for it\n",
    "vect.fit(corpus_train)\n",
    "X_train = vect.transform(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest tfidf:\n",
      "['wboc' 'delmarvas' 'atv' 'tahoe' 'wxow' 'ktvn' 'synchs' 'whig' '7news'\n",
      " 'quincy' '13m' 'wsvn' 'gram' 'fha' 'hanna' 'kwwl' 'chili' 'newson6'\n",
      " 'charlottesville' 'oates']\n",
      "Features with highest tfidf: \n",
      "['aladdin' 'asian' 'thank' 'this' 'defeat' 'hangout' 'alibaba' 'services'\n",
      " 'caper' 'eclipse' 'astronaut' 'fake' 'religious' 'windows' 'sunday'\n",
      " 'sports' 'lives' 'location' 'google' 'noah']\n"
     ]
    }
   ],
   "source": [
    "'''*** This cell is only there to visualize the min_df param. It has no real meaning outside of that scope ***'''\n",
    "\n",
    "# find maximum value for each of the features over the dataset\n",
    "max_value = X_train.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "# get feature names\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "print(\"Features with lowest tfidf:\\n{}\".format(\n",
    "    feature_names[sorted_by_tfidf[:20]]))\n",
    "\n",
    "print(\"Features with highest tfidf: \\n{}\".format(\n",
    "    feature_names[sorted_by_tfidf[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.95\n",
      "Best parameters:  {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "''' ***DO NOT RUN THIS CELLBLOCK IF YOU CAN AVOID IT*** '''\n",
    "\n",
    "# Searches for the best value for C for logistic regression\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.95\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Best cross-validation score: 0.95\n",
    "Best parameters:  {'C': 10}\n",
    "'''\n",
    "\n",
    "X_test = vect.transform(corpus_test) # Vectorizing the test data\n",
    "print(\"Test score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Discussion\n",
    "\n",
    "Reflect on your results, and how one might continue to improve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "For each group member, describe what they did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final meme\n",
    "\n",
    "Include here a meme describing your experience in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
